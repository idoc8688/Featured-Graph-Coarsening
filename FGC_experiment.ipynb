{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d0145e5",
   "metadata": {},
   "source": [
    "# FGC Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351c4059",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ace42d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deeprobust"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot install deeprobust==0.1.1, deeprobust==0.2.0, deeprobust==0.2.1, deeprobust==0.2.2, deeprobust==0.2.3, deeprobust==0.2.4, deeprobust==0.2.5, deeprobust==0.2.6, deeprobust==0.2.7, deeprobust==0.2.8 and deeprobust==0.2.9 because these package versions have conflicting dependencies.\n",
      "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached deeprobust-0.2.9-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting matplotlib>=3.1.1 (from deeprobust)\n",
      "  Downloading matplotlib-3.8.2-cp312-cp312-win_amd64.whl.metadata (5.9 kB)\n",
      "Collecting numpy>=1.17.1 (from deeprobust)\n",
      "  Downloading numpy-1.26.3-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.2 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/61.2 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/61.2 kB ? eta -:--:--\n",
      "     ------------------------- ------------ 41.0/61.2 kB 326.8 kB/s eta 0:00:01\n",
      "     -------------------------------------- 61.2/61.2 kB 407.8 kB/s eta 0:00:00\n",
      "INFO: pip is looking at multiple versions of deeprobust to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting deeprobust\n",
      "  Downloading deeprobust-0.2.8-py3-none-any.whl (211 kB)\n",
      "     ---------------------------------------- 0.0/211.5 kB ? eta -:--:--\n",
      "     ------- ------------------------------- 41.0/211.5 kB 2.0 MB/s eta 0:00:01\n",
      "     -------------------- ----------------- 112.6/211.5 kB 1.3 MB/s eta 0:00:01\n",
      "     ------------------------------- ------ 174.1/211.5 kB 1.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- 211.5/211.5 kB 1.1 MB/s eta 0:00:00\n",
      "  Downloading deeprobust-0.2.7-py3-none-any.whl (208 kB)\n",
      "     ---------------------------------------- 0.0/208.9 kB ? eta -:--:--\n",
      "     ------- -------------------------------- 41.0/208.9 kB ? eta -:--:--\n",
      "     -------------------- ----------------- 112.6/208.9 kB 2.2 MB/s eta 0:00:01\n",
      "     ------------------------------- ------ 174.1/208.9 kB 1.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- 208.9/208.9 kB 1.2 MB/s eta 0:00:00\n",
      "  Downloading deeprobust-0.2.6-py3-none-any.whl (191 kB)\n",
      "     ---------------------------------------- 0.0/191.8 kB ? eta -:--:--\n",
      "     -------- ------------------------------- 41.0/191.8 kB ? eta -:--:--\n",
      "     ---------------------- --------------- 112.6/191.8 kB 1.7 MB/s eta 0:00:01\n",
      "     ---------------------------------- --- 174.1/191.8 kB 1.5 MB/s eta 0:00:01\n",
      "     ------------------------------------ - 184.3/191.8 kB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ 191.8/191.8 kB 970.9 kB/s eta 0:00:00\n",
      "  Downloading deeprobust-0.2.5-py3-none-any.whl (191 kB)\n",
      "     ---------------------------------------- 0.0/191.8 kB ? eta -:--:--\n",
      "     -------- ------------------------------- 41.0/191.8 kB ? eta -:--:--\n",
      "     ---------------------- --------------- 112.6/191.8 kB 1.7 MB/s eta 0:00:01\n",
      "     ---------------------------------- --- 174.1/191.8 kB 1.2 MB/s eta 0:00:01\n",
      "     ------------------------------------ 191.8/191.8 kB 970.8 kB/s eta 0:00:00\n",
      "  Downloading deeprobust-0.2.4-py3-none-any.whl (191 kB)\n",
      "     ---------------------------------------- 0.0/191.5 kB ? eta -:--:--\n",
      "     -------- ------------------------------- 41.0/191.5 kB ? eta -:--:--\n",
      "     ---------------------- --------------- 112.6/191.5 kB 1.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 191.5/191.5 kB 1.5 MB/s eta 0:00:00\n",
      "  Downloading deeprobust-0.2.3-py3-none-any.whl (191 kB)\n",
      "     ---------------------------------------- 0.0/191.5 kB ? eta -:--:--\n",
      "     -------- ------------------------------- 41.0/191.5 kB ? eta -:--:--\n",
      "     ---------------------- --------------- 112.6/191.5 kB 1.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 191.5/191.5 kB 1.5 MB/s eta 0:00:00\n",
      "  Downloading deeprobust-0.2.2-py3-none-any.whl (184 kB)\n",
      "     ---------------------------------------- 0.0/184.3 kB ? eta -:--:--\n",
      "     -------- ------------------------------- 41.0/184.3 kB ? eta -:--:--\n",
      "     ----------------------- -------------- 112.6/184.3 kB 1.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 184.3/184.3 kB 1.4 MB/s eta 0:00:00\n",
      "INFO: pip is still looking at multiple versions of deeprobust to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading deeprobust-0.2.1-py3-none-any.whl (183 kB)\n",
      "     ---------------------------------------- 0.0/183.8 kB ? eta -:--:--\n",
      "     -------- ------------------------------- 41.0/183.8 kB ? eta -:--:--\n",
      "     ----------------------- -------------- 112.6/183.8 kB 1.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 183.8/183.8 kB 1.1 MB/s eta 0:00:00\n",
      "  Downloading deeprobust-0.2.0-py3-none-any.whl (183 kB)\n",
      "     ---------------------------------------- 0.0/183.8 kB ? eta -:--:--\n",
      "     -------- ------------------------------- 41.0/183.8 kB ? eta -:--:--\n",
      "     ----------------------- -------------- 112.6/183.8 kB 1.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 183.8/183.8 kB 1.2 MB/s eta 0:00:00\n",
      "  Downloading deeprobust-0.1.1.tar.gz (112 kB)\n",
      "     ---------------------------------------- 0.0/112.2 kB ? eta -:--:--\n",
      "     -------------- ------------------------- 41.0/112.2 kB ? eta -:--:--\n",
      "     -------------------------------------- 112.2/112.2 kB 1.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "\n",
      "The conflict is caused by:\n",
      "    deeprobust 0.2.9 depends on torch>=1.2.0\n",
      "    deeprobust 0.2.8 depends on torch>=1.2.0\n",
      "    deeprobust 0.2.7 depends on torch>=1.2.0\n",
      "    deeprobust 0.2.6 depends on torch>=1.2.0\n",
      "    deeprobust 0.2.5 depends on torch>=1.2.0\n",
      "    deeprobust 0.2.4 depends on torch>=1.2.0\n",
      "    deeprobust 0.2.3 depends on torch>=1.2.0\n",
      "    deeprobust 0.2.2 depends on torch>=1.2.0\n",
      "    deeprobust 0.2.1 depends on torch>=1.2.0\n",
      "    deeprobust 0.2.0 depends on torch>=1.2.0\n",
      "    deeprobust 0.1.1 depends on torch>=1.2.0\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install deeprobust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb3a42d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mor\\AppData\\Local\\Temp\\ipykernel_19236\\3090707157.py:4: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "from networkx.generators.random_graphs import erdos_renyi_graph\n",
    "from networkx.generators.random_graphs import barabasi_albert_graph\n",
    "from networkx.generators.community import stochastic_block_model\n",
    "from networkx.generators.random_graphs import watts_strogatz_graph\n",
    "from networkx.generators.community import random_partition_graph\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "\n",
    "\n",
    "import random\n",
    "from deeprobust.graph.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149fa0d5",
   "metadata": {},
   "source": [
    "# Real Datasets Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e87ba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'cora' #other datatsets : 'citeseer' , 'polblogs' , 'acm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d18ce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_nodes = 2708 #original number of nodes.\n",
    "## citeseer : 3312\n",
    "## cora     : 2708\n",
    "## polblogs : 1490\n",
    "## acm      : 3025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "188b1d19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[5. 0. 0. ... 0. 0. 0.]\n",
      " [0. 4. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 6. 0. 0.]\n",
      " [0. 0. 0. ... 0. 5. 0.]\n",
      " [0. 0. 0. ... 0. 0. 3.]]\n"
     ]
    }
   ],
   "source": [
    "data = Dataset(root='', name=dataset_name, setting='gcn',seed=10)\n",
    "adj, features, labels = data.adj, data.features, data.labels\n",
    "idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "\n",
    "A = np.array(adj.todense())\n",
    "X=np.array(features.todense())\n",
    "np.save(\"A.npy\", A)\n",
    "print(A)\n",
    "#np.save(\"X.npy\", X)\n",
    "print(X)\n",
    "import numpy as np\n",
    "b=np.ones(ori_nodes)\n",
    "\n",
    "z=A@b\n",
    "D=np.diag(z)\n",
    "L=D-A\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b9024e",
   "metadata": {},
   "source": [
    "##### RUN BELOW CELL ONLY FOR POLBLOGS AS FEATURES NEED TO CREATED FOR POLBLOGS DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bba8c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 5000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 5000\n",
    "X = np.random.multivariate_normal(np.zeros(1490), np.linalg.pinv(L), n).T\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10b3436",
   "metadata": {},
   "source": [
    "#### Minnesota, Airfoil and Bunny datasets have been taken from pygsp library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635d90ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygsp as gsp\n",
    "from pygsp import graphs\n",
    "G=graphs.Airfoil()\n",
    "print(G.N)\n",
    "L=G.L.toarray()\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a7f86d",
   "metadata": {},
   "source": [
    "# Creating Synthetic Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0f9328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Input parameters.\n",
    "p=1000 # number of nodes\n",
    "param = 0.1  \n",
    "#graph = erdos_renyi_graph(p, param, directed = False)\n",
    "#graph = nx.barabasi_albert_graph(n=p,m=20)\n",
    "#graph = watts_strogatz_graph(p,20,param,seed=12)\n",
    "graph=nx.random_geometric_graph(p,param)\n",
    "\n",
    "\n",
    "# DISPLAY GENERATED GRAPH.\n",
    "print(graph.edges)\n",
    "print(graph.nodes)\n",
    "# PLOTTING GENERATED GRAPH.\n",
    "nx.draw(graph, with_labels = True)\n",
    "plt.title(\"Laplacian\")\n",
    "plt.show()\n",
    "# CREATING EDGE WEIGHTS.\n",
    "W = np.zeros((p, p))\n",
    "for (x, y) in graph.edges:\n",
    "    W[x][y] = np.random.randint(1,10)       #weight of edge between x and y\n",
    "W_t = W + W.T\n",
    "# CALCULATING LAPLACIAN MATRIX OF GENERATED GRAPH.\n",
    "L = np.diag(W_t@np.ones((W_t.shape[0]))) - W_t\n",
    "print(L)\n",
    "print(L.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7801340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Fetures for any synthetic graph:\n",
    "n = 5000 # number of features of each node.\n",
    "X = np.random.multivariate_normal(np.zeros(p), np.linalg.pinv(L), n).T\n",
    "X.shape\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac0eae1",
   "metadata": {},
   "source": [
    "# FGC Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9da57719",
   "metadata": {},
   "outputs": [],
   "source": [
    "class solver_v2:\n",
    "\n",
    "  def __init__(self, X, k, lambda_param, beta_param, alpha_param, gamma_param):\n",
    "    self.X = X\n",
    "    self.p = X.shape[0]\n",
    "    self.k = k\n",
    "    self.n = X.shape[1]\n",
    "    \n",
    "    n = self.n\n",
    "    k = self.k\n",
    "    p = self.p\n",
    "    \n",
    "    self.thresh = 1e-10 # The 0-level\n",
    "\n",
    "    # Basic initialization (Completely random)\n",
    "    self.X_tilde = np.random.normal(0, 1, (k, n))\n",
    "    \n",
    "    self.C = np.random.normal(0,1,(p,k))\n",
    "    self.C[self.C < self.thresh] = self.thresh\n",
    "    \n",
    "    self.w = np.random.normal(10, 1, (k*(k-1))//2)\n",
    "    self.w[self.w < self.thresh] = self.thresh\n",
    "\n",
    "\n",
    "    # Model Hyperparameters\n",
    "    self.beta_param = beta_param\n",
    "    self.alpha_param = alpha_param\n",
    "    self.lambda_param = lambda_param\n",
    "    self.gamma_param = gamma_param\n",
    "    self.iters = 0\n",
    "    self.lr0 = 1e-5\n",
    "\n",
    "  def getLR(self):\n",
    "    a = 0.99\n",
    "    return self.lr0\n",
    "\n",
    "  def calc_f(self):\n",
    "    \n",
    "    #w = self.w\n",
    "    X_tilde = self.X_tilde\n",
    "    beta_param = self.beta_param\n",
    "    #Lw = self.L_operator(w)\n",
    "    #L = np.load('L (5).npy')\n",
    "    fw = 0\n",
    "\n",
    "    fw += np.trace(X_tilde.T@self.C.T@L@self.C @X_tilde)\n",
    "    # Added the tr(X.T L X) term\n",
    "   # fw += ((beta_param*(np.linalg.norm(Lw)**2))/2)\n",
    "    # Added the Frobbenius norm term\n",
    "    J = np.outer(np.ones(self.k), np.ones(self.k))/self.k\n",
    "    fw -= self.gamma_param*np.linalg.slogdet(self.C.T@L@self.C + J)[1]\n",
    "    # Added the log_det term\n",
    "    fw += (self.alpha_param/2)*(np.linalg.norm(np.subtract(self.X, np.dot(self.C, self.X_tilde))))**2\n",
    "    # Added l2 norm || X - C*X_tilde ||\n",
    "    fw += (self.lambda_param)/2*((np.linalg.norm(np.dot(self.C, np.ones((self.k, 1)))))**2)\n",
    "    # Added L_1,2 norm || C ||\n",
    "    return fw\n",
    "\n",
    "  def update_X_tilde(self):\n",
    "    #L = np.load('L (5).npy')\n",
    "    L_tilde = self.C.T@L@self.C\n",
    "    A = 2*L_tilde/(self.alpha_param)\n",
    "    A = A + np.dot(self.C.T, self.C)\n",
    "    b = np.dot(self.C.T, self.X)\n",
    "    # Update 1\n",
    "    self.X_tilde = np.linalg.pinv(A)@b\n",
    "\n",
    "    # Update 2\n",
    "    # lr = self.getLR()\n",
    "    # self.X_tilde = self.X_tilde - lr*self.alpha_param*(A@self.X_tilde - b)\n",
    "\n",
    "    # #new update:\n",
    "    for i in range(len(self.X_tilde)):\n",
    "      self.X_tilde[i] = (self.X_tilde[i]/(np.linalg.norm(self.X_tilde[i])))\n",
    "\n",
    "\n",
    "    return None\n",
    "\n",
    "  def grad_C(self):\n",
    "    #L = np.load('L (5).npy')\n",
    "    J = np.outer(np.ones(k), np.ones(k))/k\n",
    "    v=np.linalg.pinv(self.C.T@L@self.C + J)\n",
    "    gradC = np.zeros(self.C.shape)\n",
    "    gradC += self.alpha_param*((self.C@self.X_tilde - self.X)@self.X_tilde.T)\n",
    "    gradC += (self.lambda_param) * (np.abs(self.C) @ (np.ones((self.k, self.k))))\n",
    "    gradC += -2*(self.gamma_param)*L@self.C@v\n",
    "    gradC += 2*L@self.C@self.X_tilde@self.X_tilde.T\n",
    "    \n",
    "    return gradC\n",
    "\n",
    "  def update_C(self, lr = None):\n",
    "    if not lr:\n",
    "      lr = 1/ (self.k)\n",
    "    lr = self.getLR()\n",
    "    C = self.C\n",
    "    C = C - lr*self.grad_C()\n",
    "    C[C<self.thresh] = self.thresh\n",
    "    self.C = C\n",
    "    C = self.C.copy()\n",
    "\n",
    "    for i in range(len(C)):\n",
    "      C[i] = C[i]/np.linalg.norm(C[i],1)\n",
    "\n",
    "    self.C = C.copy()\n",
    "    return None\n",
    "\n",
    "  \n",
    "  def fit(self, max_iters):\n",
    "    ls = []\n",
    "    MAX_ITER_INT = 100\n",
    "    for i in tqdm(range(max_iters)):\n",
    "      #for _ in range(MAX_ITER_INT):\n",
    "        #self.update_w()\n",
    "      for _ in range(MAX_ITER_INT):\n",
    "        self.update_C(1/self.k)\n",
    "      # for _ in range(MAX_ITER_INT):\n",
    "      self.update_X_tilde()\n",
    "      ls.append(self.calc_f())\n",
    "      self.iters+=1\n",
    "      #print(self.C@self.C.T)\n",
    "      #print()\n",
    "\n",
    "    return (self.C, self.X_tilde, ls )\n",
    "\n",
    "  def New_fit(self):\n",
    "    ls=[]\n",
    "    MAX_ITER_INT = 100\n",
    "    while(True):\n",
    "      C_prev=self.C\n",
    "      self.update_C(1/self.k)\n",
    "      self.update_X_tilde()\n",
    "      ls.append(self.calc_f())\n",
    "      self.iters+=1\n",
    "      if(np.linalg.norm(self.C-C_prev)<0.1): # we have set the threshold for stopping criteria as 0.1.\n",
    "          return (self.C, self.X_tilde, ls )      \n",
    "    return (self.C, self.X_tilde, ls )    \n",
    "\n",
    "  def set_experiment(self, X, X_t):\n",
    "    self.X = X\n",
    "    self.X_tilde = X_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cd6467",
   "metadata": {},
   "source": [
    "FGC has only 3 hyperparameters lambda, alpha and gamma. beta is not any hyperparameter (it is of no use), you can put it equal to any number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfa6dae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [14:46<00:00, 88.70s/it]\n"
     ]
    }
   ],
   "source": [
    "# Below shown for Cora.\n",
    "k = 812 # Coarsened graph's number of nodes i.e. k = r*ori_nodes\n",
    "overall_loss = []\n",
    "iterations = 10 # Number of iterations our objective function will run.\n",
    "#print(\"Shape of the data matrix (p x n): \", X_now.shape)\n",
    "\n",
    "# Hyperparameters: lambda, beta, alpha, gamma\n",
    "obj = solver_v2(X, k, 500, 0, 500, X.shape[1]/2) \n",
    "C_0, X_t_0, loss_ls = obj.fit(iterations)\n",
    "overall_loss.extend(loss_ls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7683226",
   "metadata": {},
   "source": [
    "Note: If you want to work with mentioned stopping criteria from the paper, then you can use obj.New_fit() in place of obj.fit(). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845ebca5",
   "metadata": {},
   "source": [
    "### In below cell, we are computing REE and DE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4f2d309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " eigen_error \n",
      "(0.09344485166350994+0j)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:102: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30670.12849126975\n",
      "6113760.193609843\n",
      "1219.5608020877253\n"
     ]
    }
   ],
   "source": [
    "eigen_values,eigenvectors=np.linalg.eig(L)\n",
    "\n",
    "s=np.sort(eigen_values)\n",
    "\n",
    "eigen_value,eigenvector=np.linalg.eig(C_0.T@L@C_0)\n",
    "\n",
    "z=np.sort(eigen_value) \n",
    "\n",
    "\n",
    "s_new=s[-100:]\n",
    "z_new=z[-100:]\n",
    "\n",
    "temp=0\n",
    "for j in range(len(s_new)):\n",
    "  temp=temp+(abs(z_new[j]-s_new[j])/s_new[j])\n",
    "eigenerror=temp/len(s_new)\n",
    "print(\" eigen_error \")\n",
    "print(eigenerror)\n",
    "\n",
    "plt.plot(s_new, label=\"original\")\n",
    "plt.plot(z_new, label=\"coarsened\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(np.trace(X_t_0.T@C_0.T@L@C_0@X_t_0))\n",
    "print(np.trace(X.T@L@X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a859d8f7",
   "metadata": {},
   "source": [
    "### Below, we are plotting heat map of C^TC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab94c4ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'C_0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpylab\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# sns.heatmap(C_0.T@C_0)\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m a \u001b[38;5;241m=\u001b[39m sns\u001b[38;5;241m.\u001b[39mheatmap(\u001b[43mC_0\u001b[49m\u001b[38;5;241m.\u001b[39mT\u001b[38;5;129m@C_0\u001b[39m,cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCMRmap_r\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#plt.title(\"Cora\", x=0.5, y=0.9,weight=\"bold\")\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# a.figure.savefig(\"polblogs_heatmap_03.eps\",dpi=1500)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'C_0' is not defined"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "# sns.heatmap(C_0.T@C_0)\n",
    "a = sns.heatmap(C_0.T@C_0,cmap='CMRmap_r')\n",
    "#plt.title(\"Cora\", x=0.5, y=0.9,weight=\"bold\")\n",
    "# a.figure.savefig(\"polblogs_heatmap_03.eps\",dpi=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e42a33e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b688bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8371261f",
   "metadata": {},
   "source": [
    "### Plotting loss for r = 0.3,0.5,0.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e0e2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans is a list of 3 arrays which corresponds to loss values for FGC at r=0.3, 0.5 and 0.7. \n",
    "l3=Ans[0] # loss values for FGC at r=0.3\n",
    "l5=Ans[1] # loss values for FGC at r=0.5\n",
    "l7=Ans[2] # loss values for FGC at r=0.7\n",
    "plt.plot(np.log(l3),':',label='Coarsening ratio: 0.3')\n",
    "plt.plot(np.log(l5),'-.',label='Coarsening ratio: 0.5')\n",
    "plt.plot(np.log(l7),'--',label='Coarsening ratio: 0.7')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('log(Loss)')\n",
    "plt.savefig('final_citeseer_losscurve.eps', dpi=1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e9a5bc",
   "metadata": {},
   "source": [
    "### plotting top-100 eigen values curves for r=0.3,0.5,0.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad89c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.load('X (5).npy')\n",
    "#L = np.load('L (5).npy')\n",
    "eigen_values,eigenvectors=np.linalg.eig(L)\n",
    "#sort=eigen_values.argsort()[::-1]\n",
    "#eigen_values = eigen_values[sort] \n",
    "#print(eigen_values)\n",
    "s=np.sort(eigen_values)\n",
    "# print(s)\n",
    "#print(eigen_values.dtype)\n",
    "eigen_value,eigenvector=np.linalg.eig(C_0.T@L@C_0)\n",
    "#sorted=eigen_value.argsort()[::-1] \n",
    "#eigen_value = eigen_value[sorted]\n",
    "z=np.sort(eigen_value) \n",
    "#print(z)\n",
    "s_new=s[-100:]\n",
    "z_new=z[-100:]\n",
    "temp=0\n",
    "for j in range(len(s_new)):\n",
    "  temp=temp+(abs(z_new[j]-s_new[j])/s_new[j])\n",
    "eigenerror1=temp/len(s_new)\n",
    "print(\" eigen_error 1\")\n",
    "print(eigenerror1)\n",
    "#X = np.load('X (5).npy')\n",
    "#L = np.load('L (5).npy')\n",
    "#eigen_values,eigenvectors=np.linalg.eig(L)\n",
    "#sort=eigen_values.argsort()[::-1]\n",
    "#eigen_values = eigen_values[sort] \n",
    "#print(eigen_values)\n",
    "#s=np.sort(eigen_values)\n",
    "#print(s)\n",
    "#print(eigen_values.dtype)\n",
    "\n",
    "\n",
    "#2\n",
    "eigen_value2,eigenvector2=np.linalg.eig(C1@L@C1.T)\n",
    "#sorted=eigen_value.argsort()[::-1] \n",
    "#eigen_value = eigen_value[sorted]\n",
    "zc2=np.sort(eigen_value2) \n",
    "#print(z)\n",
    "#s_new=s[1:100]\n",
    "zc_new2=zc2[-100:]\n",
    "temp2=0\n",
    "for j in range(len(s_new)):\n",
    "  temp2=temp2+(abs(zc_new2[j]-s_new[j])/s_new[j])\n",
    "eigenerror2=temp2/len(s_new)\n",
    "\n",
    "\n",
    "#3\n",
    "eigen_value3,eigenvector3=np.linalg.eig(C2@L@C2.T)\n",
    "#sorted=eigen_value.argsort()[::-1] \n",
    "#eigen_value = eigen_value[sorted]\n",
    "zc3=np.sort(eigen_value3) \n",
    "#print(z)\n",
    "#s_new=s[1:100]\n",
    "zc_new3=zc3[-100:]\n",
    "temp3=0\n",
    "for j in range(len(s_new)):\n",
    "  temp3=temp3+(abs(zc_new3[j]-s_new[j])/s_new[j])\n",
    "eigenerror3=temp3/len(s_new)\n",
    "\n",
    "\n",
    "\n",
    "print(\" eigen_error \")\n",
    "print(eigenerror1)\n",
    "print(eigenerror2)\n",
    "print(eigenerror3)\n",
    "plt.plot(s_new,label=\"Original\")\n",
    "plt.plot(z_new,':', label=\"FGC\")\n",
    "plt.plot(zc_new2,'-.', label=\"LVE\")\n",
    "plt.plot(zc_new3,'--', label=\"LVN\")\n",
    "plt.title(\"Citeseer\", x=0.5, y=0.9,weight=\"bold\")\n",
    "# plt.ylabel('Relative eigen-value error')\n",
    "# plt.xlabel('Nth eigenvalue')\n",
    "plt.legend()\n",
    "plt.legend()\n",
    "plt.savefig('citeseer_eigenvalues.eps', dpi=1500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e4bb69",
   "metadata": {},
   "source": [
    "# epsilon plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8ad031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Cora.\n",
    "Ans=[] # It will store loss for different coarsening ratios.\n",
    "#n=5000\n",
    "k=[270,541,812,1083,1354,1624] # [0.1*ori_nodes,0.2*ori_nodes,0.3*ori_nodes,0.4*ori_nodes,0.5*ori_nodes,0.6*ori_nodes]\n",
    "for j in k:\n",
    "    #X = np.random.multivariate_normal(np.zeros(1490), np.linalg.pinv(L), n).T\n",
    "    #k = 300\n",
    "    overall_loss = []\n",
    "    iterations = 10\n",
    "    #print(\"Shape of the data matrix (p x n): \", X_now.shape)\n",
    "\n",
    "    # Hyperparameters: lambda, beta, alpha, gamma\n",
    "    obj = solver_v2(X, j, 500, 20, 500, X.shape[1]/2) \n",
    "    C_0, X_t_0, loss_ls = obj.fit(iterations)\n",
    "    overall_loss.extend(loss_ls)\n",
    "    AA=(X-(C_0@X_t_0))\n",
    "    Ans=Ans+[np.trace((AA.T)@L@AA)/np.trace((X.T)@L@X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3604a6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([0.1,0.2,0.3,0.4,0.5,0.6],Ans,'o-',label='Cora',color='b')\n",
    "plt.legend(loc=\"lower left\",fontsize=8)\n",
    "plt.xlabel('Coarsening Ratio')\n",
    "plt.ylabel('Epsilon')\n",
    "plt.savefig('Epsilon_Cora.eps', dpi=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e637a2",
   "metadata": {},
   "source": [
    "## Hyperbolic Error using feature matrix X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa83b6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HE(u,v):\n",
    "    return np.arccosh(1+((pow(np.linalg.norm((u-v)@X),2)*pow(np.linalg.norm(X),2))/(2*np.trace(X.T@u@X)*np.trace(X.T@v@X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f15ab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "P=np.linalg.pinv(C_0)\n",
    "L_lift=P.T@C_0.T@L@C_0@P\n",
    "HE(L_lift,L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3a42ef",
   "metadata": {},
   "source": [
    "## Reconstructional Error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2fd108",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For cora\n",
    "p=2708 # put p = no. of nodes in the graph network. \n",
    "P=np.linalg.pinv(C_0)\n",
    "L_lift=P.T@C_0.T@L@C_0@P\n",
    "LL=(L-L_lift)\n",
    "np.log(pow(np.linalg.norm(LL),2)/p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ba6a0a",
   "metadata": {},
   "source": [
    "### Zachary's Karate Club dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e283d3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scipy.sparse import csr_matrix\n",
    "from collections import Counter\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch\n",
    "from scipy.sparse import csr_matrix\n",
    "from collections import Counter\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.datasets import KarateClub\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dataset = KarateClub()\n",
    "n_classes = len(set(np.array(dataset[0].y)))\n",
    "data = dataset[0].to(device)\n",
    "A=to_dense_adj(data.edge_index)[0]\n",
    "X=data.x  \n",
    "A=A.numpy()\n",
    "print((A!=0).sum())\n",
    "print(X)\n",
    "import numpy as np\n",
    "b=np.ones(34)\n",
    "z=A@b\n",
    "D=np.diag(z)\n",
    "L=D-A\n",
    "print(L)\n",
    "\n",
    "\n",
    "# Comment these two lines to have graph data with 4 classes.\n",
    "data.y[data.y==3]=1\n",
    "data.y[data.y==2]=0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y=data.y.numpy()\n",
    "print(y)\n",
    "\n",
    "# Creating features for zachary's karate club dataset.\n",
    "\n",
    "X=np.random.multivariate_normal(np.zeros(34), np.linalg.pinv(L), 600).T;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a164cf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After getting C_0 (loading matrix), below code will classify nodes into 2 classes using C_0.  \n",
    "# Below y is a vector of actual labels of nodes in original graph G.\n",
    "import numpy\n",
    "def f(r):\n",
    "    m=max(r)\n",
    "    if(r[0]==m):\n",
    "        return 0\n",
    "    elif(r[1]==m):\n",
    "        return 1\n",
    "print(numpy.apply_along_axis(f, 1, C_0)) # Labels given by FGC.\n",
    "print(y)# Original labels.\n",
    "print(max((numpy.apply_along_axis(f, 1, C_0)==y).sum(),(numpy.apply_along_axis(f, 1, C_0)!=y).sum())) # Number of correctly classified nodes.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7644d60e",
   "metadata": {},
   "source": [
    "#### Effects of Hyperparameters "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80e63f3",
   "metadata": {},
   "source": [
    "Below, code for change of gamma is written. For change in alpha/lambda, place iterator 'i' inplace of that parameter. Hyperparameters for best case (gamma, alpha, lambda)=(600,500,1000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d86c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below shown for BA.\n",
    "C=[]\n",
    "Xc=[]\n",
    "overall_loss = []\n",
    "for i in [100,200,300,400,500,600,700,800,900,1000,2000,5000,10000,50000]:\n",
    "    k = 700 \n",
    "    iterations = 10 \n",
    "    obj = solver_v2(X, k, i,0, 500, 1000) \n",
    "    C_0, X_t_0, loss_ls = obj.fit(iterations)\n",
    "    overall_loss.extend(loss_ls)\n",
    "    C=C+[C_0]\n",
    "    Xc=Xc+[X_t_0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e9ce43",
   "metadata": {},
   "outputs": [],
   "source": [
    "I=[100,200,300,400,500,600,700,800,900,1000,2000,5000,10000,50000]\n",
    "i=0\n",
    "C_0=C_gamma[13]\n",
    "X_t_0=Xc_gamma[13]\n",
    "while(i<14):\n",
    "    eigen_values,eigenvectors=np.linalg.eig(L)\n",
    "    s=np.sort(eigen_values)\n",
    "    s_new=s[-105:-5]\n",
    "    plt.plot(s_new, label=\"Original\")\n",
    "    print(I[i])\n",
    "    eigen_value,eigenvector=np.linalg.eig(C_0.T@L@C_0)\n",
    "    z=np.sort(eigen_value) \n",
    "    z_new=z[-105:-5]\n",
    "    temp=0\n",
    "    for j in range(len(s_new)):\n",
    "      temp=temp+(abs(z_new[j]-s_new[j])/s_new[j])\n",
    "    eigenerror=temp/len(s_new)\n",
    "    print(\" eigen_error \")\n",
    "    print(eigenerror)\n",
    "    print(np.trace(X_t_0.T@C_0.T@L@C_0@X_t_0))\n",
    "    plt.plot(z_new, label=\"Coarsened\")\n",
    "    i=i+1\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216a543c",
   "metadata": {},
   "source": [
    "### Graclus and Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e94497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We used Graclus from torch_geometric library.\n",
    "from torch_geometric.nn import graclus\n",
    "from scipy import sparse\n",
    "Wc=sparse.csr_matrix(A)\n",
    "Wc = Wc.tocoo()\n",
    "row = torch.from_numpy(Wc.row).to(torch.long)\n",
    "col = torch.from_numpy(Wc.col).to(torch.long)\n",
    "edge_index_coarsen1 = torch.stack([row, col], dim=0)\n",
    "edge_weight = torch.from_numpy(Wc.data)\n",
    "a=graclus(edge_index_coarsen1,weight=edge_weight,num_nodes=1490)\n",
    "b = list(set(a.numpy()))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63795329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import fractional_matrix_power\n",
    "from sklearn.cluster import KMeans\n",
    "# A is weight matrix and L is laplacian matrix of the original graph.\n",
    "dMat = np.diag(np.sum(A, axis=0))\n",
    "dMat_inv_sqrt = fractional_matrix_power(dMat, -0.5)\n",
    "laplacian_ncut = np.identity(dMat.shape[0]) - dMat_inv_sqrt @ A @ dMat_inv_sqrt\n",
    "\n",
    "def spectral_clustering(laplacian):\n",
    "    eigVals, eigVecs = np.linalg.eig(laplacian)\n",
    "    eigVals=eigVals.real \n",
    "    eigVecs=eigVecs.real\n",
    "    # find the second smallest eigenvalue\n",
    "    eigValInds = list(zip(range(eigVals.size), eigVals.tolist()))\n",
    "    eigValInds.sort(key=lambda x : x[1])\n",
    "    #print(eigValInds)\n",
    "    eigInd = eigValInds[1][0]\n",
    "    vec = eigVecs[:, eigInd].reshape((-1, 1))\n",
    "    #print(vec)\n",
    "    kmeans = KMeans(n_clusters=2)\n",
    "    kmeans.fit(vec)\n",
    "    assignment = kmeans.predict(vec)\n",
    "    group1 = np.where(assignment == 0)[0] + 1\n",
    "    group2 = np.where(assignment == 1)[0] + 1\n",
    "    print('people in group 1:', group1)\n",
    "    print('people in group 2:', group2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3240ef22",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spectral_clustering' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mspectral_clustering\u001b[49m(L)  \n",
      "\u001b[1;31mNameError\u001b[0m: name 'spectral_clustering' is not defined"
     ]
    }
   ],
   "source": [
    "spectral_clustering(L)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcee1502",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_clustering(laplacian_ncut)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2dad4a",
   "metadata": {},
   "source": [
    "You can refer this link for more details for spectral clustering code.\n",
    "https://www.alanshawn.com/jupyter-nb-show/2019/10/31/spectral-clustering.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd00111f",
   "metadata": {},
   "source": [
    "## Adversarial attack for FGC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aa9895",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "from networkx.generators.random_graphs import erdos_renyi_graph\n",
    "from networkx.generators.random_graphs import barabasi_albert_graph\n",
    "from networkx.generators.community import stochastic_block_model\n",
    "from networkx.generators.random_graphs import watts_strogatz_graph\n",
    "from networkx.generators.community import random_partition_graph\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "\n",
    "\n",
    "import random\n",
    "from deeprobust.graph.data import Dataset\n",
    "dataset_name ='citeseer' #other datatsets : 'citeseer' , 'polblogs' , 'acm'\n",
    "ori_nodes =3312 #original number of nodes.\n",
    "data = Dataset(root='', name=dataset_name, setting='gcn',seed=10)\n",
    "adj, features, labels = data.adj, data.features, data.labels\n",
    "idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "\n",
    "A = np.array(adj.todense())\n",
    "X=np.array(features.todense())\n",
    "np.save(\"A.npy\", A)\n",
    "print((A!=0).sum())\n",
    "A_copy=A.copy()\n",
    "\n",
    "attack='random'\n",
    "rate=0.1 # 0.1->10%, 0.05->5%.\n",
    "from scipy import sparse\n",
    "from deeprobust.graph.data import Dataset, PrePtbDataset\n",
    "if attack == 'random':\n",
    "    from deeprobust.graph.global_attack import Random\n",
    "    import random; \n",
    "    np.random.seed(10)\n",
    "    attacker = Random()\n",
    "    A=sparse.csr_matrix(A)\n",
    "    A = A.tocoo()\n",
    "    n_perturbations = int(rate * (A.sum()//2))\n",
    "    attacker.attack(A, n_perturbations, type='add')\n",
    "    A = attacker.modified_adj\n",
    "    A=A.toarray()\n",
    "    print((A==1).sum())\n",
    "print(A.shape)\n",
    "\n",
    "\n",
    "print((A!=0).sum())\n",
    "#np.save(\"X.npy\", X)\n",
    "print(X)\n",
    "\n",
    "# Above is perturbed graph laplacian matrix.\n",
    "# Below is clean graph laplacian matrix.\n",
    "import numpy as np\n",
    "b=np.ones(ori_nodes)\n",
    "\n",
    "z=A@b\n",
    "D=np.diag(z)\n",
    "\n",
    "L=D-A\n",
    "print(L)\n",
    "\n",
    "b_copy=np.ones(ori_nodes)\n",
    "\n",
    "z_copy=A_copy@b_copy\n",
    "D_copy=np.diag(z_copy)\n",
    "\n",
    "L_copy=D_copy-A_copy\n",
    "print(L_copy)\n",
    "\n",
    "\n",
    "# Here we will obtain laplacian matrices, L_copy and L for clean and attacked graph data.\n",
    "# We will compare L_copy and Lc obtained from L in REE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7def8e",
   "metadata": {},
   "source": [
    "# GC Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b09fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class solver_v2:\n",
    "\n",
    "  def __init__(self, k, lambda_param, beta_param, alpha_param, gamma_param):\n",
    "#     self.X = X\n",
    "#     self.p = X.shape[0]\n",
    "    self.k = k\n",
    "#     self.n = X.shape[1]\n",
    "    self.p = L.shape[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "#     n = self.n\n",
    "    k = self.k\n",
    "    p = self.p\n",
    "    \n",
    "    self.thresh = 1e-10 # The 0-level\n",
    "\n",
    "    # Basic initialization (Completely random)\n",
    "#     self.X_tilde = np.random.normal(0, 1, (k, n))\n",
    "    \n",
    "    self.C = np.random.normal(0,1,(p,k))\n",
    "    self.C[self.C < self.thresh] = self.thresh\n",
    "    \n",
    "    self.w = np.random.normal(10, 1, (k*(k-1))//2)\n",
    "    self.w[self.w < self.thresh] = self.thresh\n",
    "\n",
    "\n",
    "    # Model Hyperparameters\n",
    "    self.beta_param = beta_param\n",
    "    self.alpha_param = alpha_param\n",
    "    self.lambda_param = lambda_param\n",
    "    self.gamma_param = gamma_param\n",
    "    self.iters = 0\n",
    "    self.lr0 = 1e-5\n",
    "\n",
    "  def getLR(self):\n",
    "    a = 0.99\n",
    "    return self.lr0\n",
    "\n",
    "  def calc_f(self):\n",
    "    \n",
    "    #w = self.w\n",
    "#     X_tilde = self.X_tilde\n",
    "    beta_param = self.beta_param\n",
    "    #Lw = self.L_operator(w)\n",
    "    #L = np.load('L (5).npy')\n",
    "    fw = 0\n",
    "\n",
    "#     fw += np.trace(X_tilde.T@self.C.T@L@self.C @X_tilde)\n",
    "    # Added the tr(X.T L X) term\n",
    "   # fw += ((beta_param*(np.linalg.norm(Lw)**2))/2)\n",
    "    # Added the Frobbenius norm term\n",
    "    J = np.outer(np.ones(self.k), np.ones(self.k))/self.k\n",
    "    fw -= self.gamma_param*np.linalg.slogdet(self.C.T@L@self.C + J)[1]\n",
    "    # Added the log_det term\n",
    "#     fw += (self.alpha_param/2)*(np.linalg.norm(np.subtract(self.X, np.dot(self.C, self.X_tilde))))**2\n",
    "    # Added l2 norm || X - C*X_tilde ||\n",
    "    fw += (self.lambda_param)/2*((np.linalg.norm(np.dot(self.C, np.ones((self.k, 1)))))**2)\n",
    "    # Added L_1,2 norm || C ||\n",
    "    return fw\n",
    "\n",
    "#   def update_X_tilde(self):\n",
    "#     #L = np.load('L (5).npy')\n",
    "#     L_tilde = self.C.T@L@self.C\n",
    "#     A = 2*L_tilde/(self.alpha_param)\n",
    "#     A = A + np.dot(self.C.T, self.C)\n",
    "#     b = np.dot(self.C.T, self.X)\n",
    "#     # Update 1\n",
    "#     self.X_tilde = np.linalg.pinv(A)@b\n",
    "\n",
    "#     # Update 2\n",
    "#     # lr = self.getLR()\n",
    "#     # self.X_tilde = self.X_tilde - lr*self.alpha_param*(A@self.X_tilde - b)\n",
    "\n",
    "#     # #new update:\n",
    "#     for i in range(len(self.X_tilde)):\n",
    "#       self.X_tilde[i] = (self.X_tilde[i]/(np.linalg.norm(self.X_tilde[i])))\n",
    "#     return None\n",
    "\n",
    "  def grad_C(self):\n",
    "    #L = np.load('L (5).npy')\n",
    "    J = np.outer(np.ones(k), np.ones(k))/k\n",
    "    v=np.linalg.pinv(self.C.T@L@self.C + J)\n",
    "    gradC = np.zeros(self.C.shape)\n",
    "#     gradC += self.alpha_param*((self.C@self.X_tilde - self.X)@self.X_tilde.T)\n",
    "    gradC += (self.lambda_param) * (np.abs(self.C) @ (np.ones((self.k, self.k))))\n",
    "    gradC += -2*(self.gamma_param)*L@self.C@v\n",
    "#     gradC += 2*L@self.C@self.X_tilde@self.X_tilde.T\n",
    "    \n",
    "    return gradC\n",
    "\n",
    "  def update_C(self, lr = None):\n",
    "    if not lr:\n",
    "      lr = 1/ (self.k)\n",
    "    lr = self.getLR()\n",
    "    C = self.C\n",
    "    C = C - lr*self.grad_C()\n",
    "    C[C<self.thresh] = self.thresh\n",
    "    self.C = C\n",
    "    C = self.C.copy()\n",
    "\n",
    "    for i in range(len(C)):\n",
    "      C[i] = C[i]/np.linalg.norm(C[i],1)\n",
    "\n",
    "    self.C = C.copy()\n",
    "    return None\n",
    "\n",
    "  \n",
    "  def fit(self, max_iters):\n",
    "    ls = []\n",
    "    MAX_ITER_INT = 100\n",
    "    for i in tqdm(range(max_iters)):\n",
    "      #for _ in range(MAX_ITER_INT):\n",
    "        #self.update_w()\n",
    "#       for _ in range(MAX_ITER_INT):\n",
    "      self.update_C(1/self.k)\n",
    "      # for _ in range(MAX_ITER_INT):\n",
    "#       self.update_X_tilde()\n",
    "      ls.append(self.calc_f())\n",
    "      self.iters+=1\n",
    "      #print(self.C@self.C.T)\n",
    "      #print()\n",
    "\n",
    "    return (self.C, ls )\n",
    "\n",
    "  def New_fit(self):\n",
    "    ls=[]\n",
    "    MAX_ITER_INT = 100\n",
    "    while(True):\n",
    "      C_prev=self.C\n",
    "      self.update_C(1/self.k)\n",
    "      ls.append(self.calc_f())\n",
    "      self.iters+=1\n",
    "      if(np.linalg.norm(self.C-C_prev)<0.1):\n",
    "          return (self.C, ls )      \n",
    "    return (self.C, ls )    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d74c216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below shown for Cora.\n",
    "k = 750 # Coarsened graph's number of nodes i.e. k = r*ori_nodes\n",
    "overall_loss = []\n",
    "iterations = 100 # Number of iterations our objective function will run.\n",
    "#print(\"Shape of the data matrix (p x n): \", X_now.shape)\n",
    "\n",
    "# Hyperparameters: lambda, beta, alpha, gamma\n",
    "# Only lambda and gamma hyperparameters are used. So you can ignore beta and alpha.\n",
    "obj = solver_v2( k, 300, 0, 0, 250) \n",
    "C_0, loss_ls = obj.fit(iterations)\n",
    "overall_loss.extend(loss_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86407155",
   "metadata": {},
   "source": [
    "Hyperbolic error for GC on graph datasets having no features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3bc531",
   "metadata": {},
   "outputs": [],
   "source": [
    "E=np.linalg.eig(L)\n",
    "eigen_values,eigenvectors=E\n",
    "D={}\n",
    "# N is the number of nodes in the graph. \n",
    "for c in range(N):\n",
    "    D[eigen_values[c]]=eigenvectors[c]\n",
    "# print(len(D))\n",
    "D=dict(sorted(D.items(), key=lambda item: item[0]))\n",
    "EV=D.values()\n",
    "ev=D.keys()\n",
    "ev=np.array(list(ev))\n",
    "EV=np.array(list(EV))\n",
    "ev[ev<1e-5]=0\n",
    "ind=np.argmax(ev==ev[ev!=0][0])\n",
    "x=EV[ind]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc73d8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HE(u,v):\n",
    "    return np.arccosh(1+((pow(np.linalg.norm((u-v)@x),2)*pow(np.linalg.norm(x),2))/(2*(x.T@u@x)*(x.T@v@x))))\n",
    "# Above x is eigen vector corresponding to smallest non-zero eigen value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42c9fad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f051be53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3a8018f",
   "metadata": {},
   "source": [
    "## Two stage featured graph coarsening "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fb733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tilda=np.linalg.pinv(C_0)@X\n",
    "Lc=C_0.T@L@C_0\n",
    "Xc=np.linalg.pinv(np.eye(Lc.shape[0])+Lc)@X_tilda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d04ca7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de3cfba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ed91f71",
   "metadata": {},
   "source": [
    "# FGCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68944b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class solver_v2:\n",
    "\n",
    "  def __init__(self, X, k,d, lambda_param, beta_param, alpha_param, gamma_param):\n",
    "    self.X = X\n",
    "    self.p = X.shape[0]\n",
    "    self.n = X.shape[1]\n",
    "    self.k = k\n",
    "    self.d = d\n",
    "    \n",
    "    p = self.p    \n",
    "    n = self.n\n",
    "    k = self.k\n",
    "    d = self.d\n",
    "\n",
    "    \n",
    "    self.thresh = 1e-10 # The 0-level\n",
    "\n",
    "    # Basic initialization (Completely random)\n",
    "#     self.X_tilde = np.random.normal(0, 1, (k, n))\n",
    "    self.W = np.random.normal(0, 1, (k, d))\n",
    "    self.H = np.random.normal(0, 1, (d, n))\n",
    "    \n",
    "    self.C = np.random.normal(0,1,(p,k))\n",
    "    self.C[self.C < self.thresh] = self.thresh\n",
    "    \n",
    "    self.w = np.random.normal(10, 1, (k*(k-1))//2)\n",
    "    self.w[self.w < self.thresh] = self.thresh\n",
    "    \n",
    "\n",
    "    # Model Hyperparameters\n",
    "    self.beta_param = beta_param\n",
    "    self.alpha_param = alpha_param\n",
    "    self.lambda_param = lambda_param\n",
    "    self.gamma_param = gamma_param\n",
    "    self.iters = 0\n",
    "    self.lr0 = 1e-5\n",
    "\n",
    "  def getLR(self):\n",
    "    a = 0.99\n",
    "    return self.lr0\n",
    "\n",
    "  def calc_f(self):\n",
    "    \n",
    "    #w = self.w\n",
    "#     X_tilde = self.X_tilde\n",
    "    W=self.W\n",
    "    H=self.H\n",
    "    beta_param = self.beta_param\n",
    "    #Lw = self.L_operator(w)\n",
    "    #L = np.load('L (5).npy')\n",
    "    fw = 0\n",
    "\n",
    "    fw += np.trace(W.T@self.C.T@L@self.C @W)\n",
    "    # Added the tr(X.T L X) term\n",
    "   # fw += ((beta_param*(np.linalg.norm(Lw)**2))/2)\n",
    "    # Added the Frobbenius norm term\n",
    "    J = np.outer(np.ones(self.k), np.ones(self.k))/self.k\n",
    "    fw -= self.gamma_param*np.linalg.slogdet(self.C.T@L@self.C + J)[1]\n",
    "    # Added the log_det term\n",
    "    fw += (self.alpha_param/2)*(np.linalg.norm(np.subtract(self.X, np.dot(self.C, np.dot(W,H)))))**2\n",
    "    # Added l2 norm || X - C*X_tilde ||\n",
    "    fw += (self.lambda_param)/2*((np.linalg.norm(np.dot(self.C, np.ones((self.k, 1)))))**2)\n",
    "    # Added L_1,2 norm || C ||\n",
    "    fw += ((beta_param*((np.linalg.norm(W)**2)+(np.linalg.norm(H)**2)))/2)\n",
    "    # Added Frobbenius norm terms\n",
    "    return fw\n",
    "\n",
    "  def update_X_tilde(self):\n",
    "    #L = np.load('L (5).npy')\n",
    "    L_tilde = self.C.T@L@self.C\n",
    "    A = 2*L_tilde/(self.alpha_param)\n",
    "    A = A + np.dot(self.C.T, self.C)\n",
    "    b = np.dot(self.C.T, self.X)\n",
    "    # Update 1\n",
    "    self.X_tilde = np.linalg.pinv(A)@b\n",
    "\n",
    "    # Update 2\n",
    "    # lr = self.getLR()\n",
    "    # self.X_tilde = self.X_tilde - lr*self.alpha_param*(A@self.X_tilde - b)\n",
    "\n",
    "    # #new update:\n",
    "    for i in range(len(self.X_tilde)):\n",
    "      self.X_tilde[i] = (self.X_tilde[i]/(np.linalg.norm(self.X_tilde[i])))\n",
    "\n",
    "\n",
    "    return None\n",
    "\n",
    "  def grad_C(self):\n",
    "    #L = np.load('L (5).npy')\n",
    "    J = np.outer(np.ones(k), np.ones(k))/k\n",
    "    v=np.linalg.pinv(self.C.T@L@self.C + J)\n",
    "    gradC = np.zeros(self.C.shape)\n",
    "    gradC += self.alpha_param*((self.C@self.W@self.H - self.X)@self.H.T@self.W.T)\n",
    "    gradC += (self.lambda_param) * (np.abs(self.C) @ (np.ones((self.k, self.k))))\n",
    "    gradC += -2*(self.gamma_param)*L@self.C@v\n",
    "    gradC += 2*L@self.C@self.W@self.W.T\n",
    "    \n",
    "    return gradC\n",
    "\n",
    "  def update_C(self, lr = None):\n",
    "    if not lr:\n",
    "      lr = 1/ (self.k)\n",
    "    lr = self.getLR()\n",
    "    C = self.C\n",
    "    C = C - lr*self.grad_C()\n",
    "    C[C<self.thresh] = self.thresh\n",
    "    self.C = C\n",
    "    C = self.C.copy()\n",
    "\n",
    "    for i in range(len(C)):\n",
    "      C[i] = C[i]/np.linalg.norm(C[i],1)\n",
    "\n",
    "    self.C = C.copy()\n",
    "    return None\n",
    "\n",
    "\n",
    "  def grad_W(self):\n",
    "    #L = np.load('L (5).npy')\n",
    "    gradW = np.zeros(self.W.shape)\n",
    "    gradW -= self.alpha_param*(self.C.T@(self.C@self.W@self.H-self.X)@self.H.T)\n",
    "    gradW += 2*(self.C.T@L@self.C@self.W)\n",
    "    gradW += self.beta_param*self.W\n",
    "    return gradW\n",
    "\n",
    "  def update_W(self, lr = None):\n",
    "    if not lr:\n",
    "      lr = 1/ (self.k)\n",
    "    lr = self.getLR()\n",
    "    W = self.W\n",
    "    W = W - lr*self.grad_W()\n",
    "    W[W<self.thresh] = self.thresh\n",
    "    self.W = W\n",
    "    W = self.W.copy()\n",
    "\n",
    "    for i in range(len(W)):\n",
    "      W[i] = W[i]/np.linalg.norm(W[i],1)\n",
    "\n",
    "    self.W = W.copy()\n",
    "    return None\n",
    "\n",
    "  def grad_H(self):\n",
    "    #L = np.load('L (5).npy')\n",
    "    gradH = np.zeros(self.H.shape)\n",
    "    gradH -= self.alpha_param*(self.W.T@self.C.T@(self.C@self.W@self.H-self.X))\n",
    "    gradH += self.beta_param*self.H\n",
    "    return gradH\n",
    "\n",
    "  def update_H(self, lr = None):\n",
    "    if not lr:\n",
    "      lr = 1/ (self.k)\n",
    "    lr = self.getLR()\n",
    "    H = self.H\n",
    "    H = H - lr*self.grad_H()\n",
    "    H[H<self.thresh] = self.thresh\n",
    "    self.H = H\n",
    "    H = self.H.copy()\n",
    "\n",
    "    for i in range(len(H)):\n",
    "      H[i] = H[i]/np.linalg.norm(H[i],1)\n",
    "\n",
    "    self.H = H.copy()\n",
    "    return None\n",
    "  \n",
    "  def fit(self, max_iters):\n",
    "    ls = []\n",
    "    MAX_ITER_INT = 200\n",
    "    for i in tqdm(range(max_iters)):\n",
    "      #for _ in range(MAX_ITER_INT):\n",
    "        #self.update_w()\n",
    "      for _ in range(MAX_ITER_INT):\n",
    "        self.update_C(1/self.k)\n",
    "        self.update_W(1/self.k)\n",
    "        self.update_H(1/self.k)\n",
    "      # for _ in range(MAX_ITER_INT):\n",
    "#       self.update_X_tilde()\n",
    "      ls.append(self.calc_f())\n",
    "      self.iters+=1\n",
    "      #print(self.C@self.C.T)\n",
    "      #print()\n",
    "\n",
    "    return (self.C, self.W, self.H, ls )\n",
    "\n",
    "#   def New_fit(self):\n",
    "#     ls=[]\n",
    "#     MAX_ITER_INT = 100\n",
    "#     while(True):\n",
    "#       C_prev=self.C\n",
    "#       self.update_C(1/self.k)\n",
    "#       self.update_X_tilde()\n",
    "#       ls.append(self.calc_f())\n",
    "#       self.iters+=1\n",
    "#       if(np.linalg.norm(self.C-C_prev)<0.1):\n",
    "#           return (self.C, self.X_tilde, ls )      \n",
    "#     return (self.C, self.X_tilde, ls )    \n",
    "\n",
    "  def set_experiment(self, X, X_t):\n",
    "    self.X = X\n",
    "    self.X_tilde = X_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cad89c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below shown for Cora.\n",
    "k = 812 # Coarsened graph's number of nodes i.e. k = r*ori_nodes\n",
    "d= 429 # Reduced number of features in coarsened graph\n",
    "overall_loss = []\n",
    "iterations = 5 # Number of iterations our objective function will run.\n",
    "#print(\"Shape of the data matrix (p x n): \", X_now.shape)\n",
    "\n",
    "# Hyperparameters: lambda, beta, alpha, gamma\n",
    "obj = solver_v2(X,k,d, 400, 20, 800, 700) \n",
    "C_0, W_0,H_0, loss_ls = obj.fit(iterations) # W_0 is feature matrix of coarsened graph\n",
    "overall_loss.extend(loss_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb74e81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Graph_coarse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
